{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T17:22:16.983072Z","iopub.status.busy":"2024-01-17T17:22:16.982398Z","iopub.status.idle":"2024-01-17T17:22:23.830963Z","shell.execute_reply":"2024-01-17T17:22:23.830121Z","shell.execute_reply.started":"2024-01-17T17:22:16.983038Z"},"trusted":true},"outputs":[],"source":["from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from sklearn.model_selection import train_test_split\n","\n","from tqdm import trange\n","from tabulate import tabulate\n","\n","import pandas as pd\n","import numpy as np\n","import torch\n","import random"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T17:22:23.832911Z","iopub.status.busy":"2024-01-17T17:22:23.832442Z","iopub.status.idle":"2024-01-17T17:22:23.888117Z","shell.execute_reply":"2024-01-17T17:22:23.887149Z","shell.execute_reply.started":"2024-01-17T17:22:23.832884Z"},"trusted":true},"outputs":[],"source":["def get_device():\n","    if torch.cuda.is_available():\n","        device = torch.device(\"cuda\")\n","        print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","        print('We will use the GPU:', torch.cuda.get_device_name(0))\n","    else:\n","        print('No GPU available, using the CPU instead.')\n","        device = torch.device(\"cpu\")\n","    return device\n","\n","\n","device = get_device()"]},{"cell_type":"markdown","metadata":{},"source":["Loading our dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T17:22:23.890018Z","iopub.status.busy":"2024-01-17T17:22:23.889591Z","iopub.status.idle":"2024-01-17T17:22:23.959430Z","shell.execute_reply":"2024-01-17T17:22:23.958590Z","shell.execute_reply.started":"2024-01-17T17:22:23.889956Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv(\"../input/rudabank/data_tagged.csv\")\n","\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T17:22:23.962594Z","iopub.status.busy":"2024-01-17T17:22:23.961876Z","iopub.status.idle":"2024-01-17T17:22:23.983692Z","shell.execute_reply":"2024-01-17T17:22:23.982737Z","shell.execute_reply.started":"2024-01-17T17:22:23.962567Z"},"trusted":true},"outputs":[],"source":["df.groupby([\"tag\"]).count()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T17:22:23.985149Z","iopub.status.busy":"2024-01-17T17:22:23.984825Z","iopub.status.idle":"2024-01-17T17:22:24.002801Z","shell.execute_reply":"2024-01-17T17:22:24.001925Z","shell.execute_reply.started":"2024-01-17T17:22:23.985122Z"},"trusted":true},"outputs":[],"source":["df.replace(\"appreciatiom\", \"appreciation\", inplace=True)\n","df.drop(df[df[\"tag\"] == \"apology_response\"].index, inplace=True)\n","\n","df.groupby([\"tag\"]).count()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T17:22:24.004762Z","iopub.status.busy":"2024-01-17T17:22:24.004024Z","iopub.status.idle":"2024-01-17T17:22:24.023730Z","shell.execute_reply":"2024-01-17T17:22:24.022826Z","shell.execute_reply.started":"2024-01-17T17:22:24.004731Z"},"trusted":true},"outputs":[],"source":["classes = {\"apology\": 0,\n","           \"appreciation\": 1,\n","           \"avoiding\": 2,\n","           \"back-channeling\": 3,\n","           \"closing\": 4,\n","           \"command\": 5,\n","           \"disapproval\": 6,\n","           \"neg_answer\": 7,\n","           \"open_question\": 8,\n","           \"opening\": 9,\n","           \"other_answers\": 10,\n","           \"pos_answer\": 11,\n","           \"statement\": 12,\n","           \"thanking\": 13,\n","           \"yes_no_question\": 14}\n","\n","df.replace({\"tag\": classes}, inplace=True)\n","\n","df.groupby([\"tag\"]).count()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T17:22:24.025175Z","iopub.status.busy":"2024-01-17T17:22:24.024841Z","iopub.status.idle":"2024-01-17T17:22:24.029406Z","shell.execute_reply":"2024-01-17T17:22:24.028539Z","shell.execute_reply.started":"2024-01-17T17:22:24.025144Z"},"trusted":true},"outputs":[],"source":["df.reset_index(drop=True, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T17:22:24.031207Z","iopub.status.busy":"2024-01-17T17:22:24.030530Z","iopub.status.idle":"2024-01-17T17:22:24.043251Z","shell.execute_reply":"2024-01-17T17:22:24.042322Z","shell.execute_reply.started":"2024-01-17T17:22:24.031174Z"},"trusted":true},"outputs":[],"source":["utterances_df = df[[\"tagged_utterance\"]]\n","\n","utterances_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T17:22:24.045156Z","iopub.status.busy":"2024-01-17T17:22:24.044788Z","iopub.status.idle":"2024-01-17T17:22:24.059107Z","shell.execute_reply":"2024-01-17T17:22:24.058179Z","shell.execute_reply.started":"2024-01-17T17:22:24.045123Z"},"trusted":true},"outputs":[],"source":["labels_df = df[[\"tag\"]]\n","\n","labels_df"]},{"cell_type":"markdown","metadata":{},"source":["Fine-Tuning RuBERT base cased conversational for tokenizing dialog utterances:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T17:22:24.063211Z","iopub.status.busy":"2024-01-17T17:22:24.062810Z","iopub.status.idle":"2024-01-17T17:22:25.209019Z","shell.execute_reply":"2024-01-17T17:22:25.208024Z","shell.execute_reply.started":"2024-01-17T17:22:24.063182Z"},"trusted":true},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased-conversational\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T17:22:25.210475Z","iopub.status.busy":"2024-01-17T17:22:25.210198Z","iopub.status.idle":"2024-01-17T17:22:25.215747Z","shell.execute_reply":"2024-01-17T17:22:25.214626Z","shell.execute_reply.started":"2024-01-17T17:22:25.210451Z"},"trusted":true},"outputs":[],"source":["text = utterances_df.tagged_utterance.values\n","labels = labels_df.tag.values"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T17:22:25.217156Z","iopub.status.busy":"2024-01-17T17:22:25.216865Z","iopub.status.idle":"2024-01-17T17:22:25.228004Z","shell.execute_reply":"2024-01-17T17:22:25.227073Z","shell.execute_reply.started":"2024-01-17T17:22:25.217133Z"},"trusted":true},"outputs":[],"source":["def print_rand_sentence():\n","    index = random.randint(0, len(text)-1)\n","    table = np.array([tokenizer.tokenize(text[index]), \n","                      tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text[index]))]).T\n","    print(tabulate(table,\n","                   headers = ['Tokens', 'Token IDs'],\n","                   tablefmt = 'fancy_grid'))\n","\n","print_rand_sentence()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T17:22:25.229090Z","iopub.status.busy":"2024-01-17T17:22:25.228835Z","iopub.status.idle":"2024-01-17T17:22:25.242384Z","shell.execute_reply":"2024-01-17T17:22:25.241566Z","shell.execute_reply.started":"2024-01-17T17:22:25.229067Z"},"trusted":true},"outputs":[],"source":["def preprocessing(input_text, tokenizer):\n","    '''\n","    Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n","      - input_ids: list of token ids\n","      - token_type_ids: list of token type ids\n","      - attention_mask: list of indices (0,1) specifying which tokens should considered by the model (return_attention_mask = True).\n","    '''\n","    return tokenizer.encode_plus(\n","                          input_text,\n","                          add_special_tokens = True,\n","                          max_length = 32,\n","                          pad_to_max_length = True,\n","                          return_attention_mask = True,\n","                          return_tensors = 'pt'\n","                     )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T17:22:25.243932Z","iopub.status.busy":"2024-01-17T17:22:25.243574Z","iopub.status.idle":"2024-01-17T17:22:26.025334Z","shell.execute_reply":"2024-01-17T17:22:26.024572Z","shell.execute_reply.started":"2024-01-17T17:22:25.243898Z"},"trusted":true},"outputs":[],"source":["token_id = []\n","attention_masks = []\n","for sample in text:\n","    encoding_dict = preprocessing(sample, tokenizer)\n","    token_id.append(encoding_dict['input_ids']) \n","    attention_masks.append(encoding_dict['attention_mask'])\n","\n","token_id = torch.cat(token_id, dim = 0)\n","attention_masks = torch.cat(attention_masks, dim = 0)\n","labels = torch.tensor(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T17:22:26.026683Z","iopub.status.busy":"2024-01-17T17:22:26.026383Z","iopub.status.idle":"2024-01-17T17:22:26.049159Z","shell.execute_reply":"2024-01-17T17:22:26.048170Z","shell.execute_reply.started":"2024-01-17T17:22:26.026646Z"},"trusted":true},"outputs":[],"source":["def print_rand_sentence_encoding():\n","    '''Displays tokens, token IDs and attention mask of a random text sample'''\n","    index = random.randint(0, len(text) - 1)\n","    tokens = tokenizer.tokenize(tokenizer.decode(token_id[index]))\n","    token_ids = [i.numpy() for i in token_id[index]]\n","    attention = [i.numpy() for i in attention_masks[index]]\n","\n","    table = np.array([tokens, token_ids, attention]).T\n","    print(tabulate(table, \n","                   headers = ['Tokens', 'Token IDs', 'Attention Mask'],\n","                   tablefmt = 'fancy_grid'))\n","\n","print_rand_sentence_encoding()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T17:22:26.051905Z","iopub.status.busy":"2024-01-17T17:22:26.050277Z","iopub.status.idle":"2024-01-17T17:22:26.072030Z","shell.execute_reply":"2024-01-17T17:22:26.071207Z","shell.execute_reply.started":"2024-01-17T17:22:26.051878Z"},"trusted":true},"outputs":[],"source":["val_ratio = 0.2\n","\n","batch_size = 16\n","\n","train_idx, val_idx = train_test_split(\n","    np.arange(len(labels)),\n","    test_size = val_ratio,\n","    shuffle = True,\n","    stratify = labels)\n","\n","train_set = TensorDataset(token_id[train_idx], \n","                          attention_masks[train_idx], \n","                          labels[train_idx])\n","\n","val_set = TensorDataset(token_id[val_idx], \n","                        attention_masks[val_idx], \n","                        labels[val_idx])\n","\n","train_dataloader = DataLoader(\n","            train_set,\n","            sampler = RandomSampler(train_set),\n","            batch_size = batch_size\n","        )\n","\n","validation_dataloader = DataLoader(\n","            val_set,\n","            sampler = SequentialSampler(val_set),\n","            batch_size = batch_size\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T17:22:26.073400Z","iopub.status.busy":"2024-01-17T17:22:26.073114Z","iopub.status.idle":"2024-01-17T17:22:26.084642Z","shell.execute_reply":"2024-01-17T17:22:26.083726Z","shell.execute_reply.started":"2024-01-17T17:22:26.073378Z"},"trusted":true},"outputs":[],"source":["def b_tp(preds, labels):\n","    return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n","\n","def b_fp(preds, labels):\n","    return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n","\n","def b_tn(preds, labels):\n","    return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n","\n","def b_fn(preds, labels):\n","    return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n","\n","def b_metrics(preds, labels):\n","    preds = np.argmax(preds, axis = 1).flatten()\n","    labels = labels.flatten()\n","    tp = b_tp(preds, labels)\n","    tn = b_tn(preds, labels)\n","    fp = b_fp(preds, labels)\n","    fn = b_fn(preds, labels)\n","    b_accuracy = (tp + tn) / len(labels)\n","    b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n","    b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n","    b_specificity = tn / (tn + fp) if (tn + fp) > 0 else 'nan'\n","    return b_accuracy, b_precision, b_recall, b_specificity"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T17:22:26.085989Z","iopub.status.busy":"2024-01-17T17:22:26.085662Z","iopub.status.idle":"2024-01-17T17:22:31.179807Z","shell.execute_reply":"2024-01-17T17:22:31.178819Z","shell.execute_reply.started":"2024-01-17T17:22:26.085965Z"},"trusted":true},"outputs":[],"source":["model = BertForSequenceClassification.from_pretrained(\n","    \"DeepPavlov/rubert-base-cased-conversational\",\n","    num_labels = 15,\n","    output_attentions = False,\n","    output_hidden_states = False,\n",")\n","\n","optimizer = torch.optim.AdamW(model.parameters(), \n","                              lr = 5e-5,\n","                              eps = 1e-08\n","                              )\n","\n","\n","model.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T17:22:31.181364Z","iopub.status.busy":"2024-01-17T17:22:31.181046Z","iopub.status.idle":"2024-01-17T17:23:33.827977Z","shell.execute_reply":"2024-01-17T17:23:33.826944Z","shell.execute_reply.started":"2024-01-17T17:22:31.181336Z"},"trusted":true},"outputs":[],"source":["epochs = 4\n","\n","for _ in trange(epochs, desc = 'Epoch'):\n","    model.train()\n","    \n","    tr_loss = 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","\n","    for step, batch in enumerate(train_dataloader):\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","        optimizer.zero_grad()\n","        \n","        train_output = model(b_input_ids, \n","                             token_type_ids = None, \n","                             attention_mask = b_input_mask, \n","                             labels = b_labels)\n","        \n","        train_output.loss.backward()\n","        optimizer.step()\n","        \n","        tr_loss += train_output.loss.item()\n","        nb_tr_examples += b_input_ids.size(0)\n","        nb_tr_steps += 1\n","\n","        \n","    model.eval()\n","    \n","    val_accuracy = []\n","    val_precision = []\n","    val_recall = []\n","    val_specificity = []\n","\n","    for batch in validation_dataloader:\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","        with torch.no_grad():\n","            eval_output = model(b_input_ids, \n","                                token_type_ids = None, \n","                                attention_mask = b_input_mask)\n","        logits = eval_output.logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n","        val_accuracy.append(b_accuracy)\n","        \n","        if b_precision != 'nan': val_precision.append(b_precision)\n","            \n","        if b_recall != 'nan': val_recall.append(b_recall)\n","            \n","        if b_specificity != 'nan': val_specificity.append(b_specificity)\n","\n","    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n","    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n","    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n","    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n","    print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')"]},{"cell_type":"markdown","metadata":{},"source":["Final metrics are as follows:\n","- Train loss: 0.2083\n","- Validation Accuracy: 0.1228\n","- Validation Precision: 0.8235\n","- Validation Recall: 0.9062\n","- Validation Specificity: 0.8708"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T17:40:26.254781Z","iopub.status.busy":"2024-01-17T17:40:26.253943Z","iopub.status.idle":"2024-01-17T17:40:26.300017Z","shell.execute_reply":"2024-01-17T17:40:26.299090Z","shell.execute_reply.started":"2024-01-17T17:40:26.254748Z"},"trusted":true},"outputs":[],"source":["new_sentence = \"Откуда ты?\"\n","\n","test_ids = []\n","test_attention_mask = []\n","\n","encoding = preprocessing(new_sentence, tokenizer)\n","\n","test_ids.append(encoding['input_ids'])\n","test_attention_mask.append(encoding['attention_mask'])\n","test_ids = torch.cat(test_ids, dim=0)\n","test_attention_mask = torch.cat(test_attention_mask, dim=0)\n","\n","with torch.no_grad():\n","    output = model(test_ids.to(device), token_type_ids = None, attention_mask = test_attention_mask.to(device))\n","\n","prediction = np.argmax(output.logits.cpu().numpy()).flatten().item()\n","\n","print('Input Sentence: ', new_sentence)\n","print('Predicted Class: ', prediction)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T17:40:33.770219Z","iopub.status.busy":"2024-01-17T17:40:33.769871Z","iopub.status.idle":"2024-01-17T17:40:33.776488Z","shell.execute_reply":"2024-01-17T17:40:33.775581Z","shell.execute_reply.started":"2024-01-17T17:40:33.770193Z"},"trusted":true},"outputs":[],"source":["classes"]},{"cell_type":"markdown","metadata":{},"source":["As we can see, the model is able to predict the correct label for this class. Let's test the whole dialog:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T18:04:12.061619Z","iopub.status.busy":"2024-01-17T18:04:12.060643Z","iopub.status.idle":"2024-01-17T18:04:12.074955Z","shell.execute_reply":"2024-01-17T18:04:12.074030Z","shell.execute_reply.started":"2024-01-17T18:04:12.061575Z"},"trusted":true},"outputs":[],"source":["utters = np.array([[\"Извините, это место занято?\",\n","           \"Нет, пожалуйста, не стесняйтесь.\",\n","           \"Большое спасибо.\",\n","           \"Вы работаете в Шанхае?\",\n","           \"да я делаю.\",\n","           \"А как насчет тебя?\",\n","           \"Нет, я турист.\",\n","           \"Это потрясающее место!\",\n","           \"Это намного больше, чем я себе представлял, и гораздо более захватывающе!\",\n","           \"Здесь так много интересного.\",\n","           \"Ты можешь сказать это еще раз!\",\n","           \"Это гораздо современнее, чем люди себе представляют.\",\n","           \"Откуда ты?\",\n","           \"Хм, что ж, давайте посмотрим...\",\n","           \"Я родом из Канзаса.\",\n","           \"Гораздо более тихое и умиротворенное место , чем здесь , это точно!\",\n","           \"Ага...\"],\n","          [\"yes_no_question\",\n","           \"neg_answer\",\n","           \"thanking\",\n","           \"yes_no_question\",\n","           \"pos_answer\",\n","           \"open_question\",\n","           \"neg_answer\",\n","           \"appreciation\",\n","           \"statement\",\n","           \"statement\",\n","           \"back-channeling\",\n","           \"statement\",\n","           \"open_question\",\n","           \"back-channeling\",\n","           \"other_answers\",\n","           \"statement\",\n","           \"back-channeling\"]]).T\n","test_df = pd.DataFrame(utters, columns=[\"utterances\", \"tags\"])\n","\n","test_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T18:04:14.018891Z","iopub.status.busy":"2024-01-17T18:04:14.018261Z","iopub.status.idle":"2024-01-17T18:04:14.025836Z","shell.execute_reply":"2024-01-17T18:04:14.024853Z","shell.execute_reply.started":"2024-01-17T18:04:14.018855Z"},"trusted":true},"outputs":[],"source":["def get_preds(new_sentence: str):\n","    test_ids = []\n","    test_attention_mask = []\n","\n","    encoding = preprocessing(new_sentence, tokenizer)\n","\n","    test_ids.append(encoding['input_ids'])\n","    test_attention_mask.append(encoding['attention_mask'])\n","    test_ids = torch.cat(test_ids, dim=0)\n","    test_attention_mask = torch.cat(test_attention_mask, dim=0)\n","\n","    with torch.no_grad():\n","        output = model(test_ids.to(device), token_type_ids = None, attention_mask = test_attention_mask.to(device))\n","\n","    prediction = np.argmax(output.logits.cpu().numpy()).flatten().item()\n","    \n","    return prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T18:04:15.258524Z","iopub.status.busy":"2024-01-17T18:04:15.258161Z","iopub.status.idle":"2024-01-17T18:04:15.468328Z","shell.execute_reply":"2024-01-17T18:04:15.467435Z","shell.execute_reply.started":"2024-01-17T18:04:15.258494Z"},"trusted":true},"outputs":[],"source":["test_df[\"preds\"] = test_df.apply(lambda x: get_preds(x[\"utterances\"]), axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T18:04:16.852897Z","iopub.status.busy":"2024-01-17T18:04:16.852525Z","iopub.status.idle":"2024-01-17T18:04:16.864728Z","shell.execute_reply":"2024-01-17T18:04:16.863908Z","shell.execute_reply.started":"2024-01-17T18:04:16.852867Z"},"trusted":true},"outputs":[],"source":["test_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T18:04:20.984593Z","iopub.status.busy":"2024-01-17T18:04:20.983880Z","iopub.status.idle":"2024-01-17T18:04:20.990997Z","shell.execute_reply":"2024-01-17T18:04:20.990120Z","shell.execute_reply.started":"2024-01-17T18:04:20.984561Z"},"trusted":true},"outputs":[],"source":["inv_classes = {v: k for k, v in classes.items()}\n","\n","inv_classes"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T18:04:22.994612Z","iopub.status.busy":"2024-01-17T18:04:22.994271Z","iopub.status.idle":"2024-01-17T18:04:23.008274Z","shell.execute_reply":"2024-01-17T18:04:23.007314Z","shell.execute_reply.started":"2024-01-17T18:04:22.994586Z"},"trusted":true},"outputs":[],"source":["test_df.replace({\"preds\": inv_classes}, inplace=True)\n","\n","test_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T18:04:47.235957Z","iopub.status.busy":"2024-01-17T18:04:47.235582Z","iopub.status.idle":"2024-01-17T18:04:47.248851Z","shell.execute_reply":"2024-01-17T18:04:47.247932Z","shell.execute_reply.started":"2024-01-17T18:04:47.235928Z"},"trusted":true},"outputs":[],"source":["test_df[\"agreement\"] = test_df.apply(lambda x: 1 if x[\"tags\"] == x[\"preds\"] else 0, axis=1)\n","\n","test_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-17T18:07:39.646090Z","iopub.status.busy":"2024-01-17T18:07:39.645369Z","iopub.status.idle":"2024-01-17T18:07:39.651279Z","shell.execute_reply":"2024-01-17T18:07:39.650375Z","shell.execute_reply.started":"2024-01-17T18:07:39.646058Z"},"trusted":true},"outputs":[],"source":["print(\"Agreement % between actual and predicted tags: {}\".format(test_df[\"agreement\"].sum() / len(test_df) * 100))"]},{"cell_type":"markdown","metadata":{},"source":["70.6% of the model's predictions match the actual labels. While this can be considered rather accurate, this metric can definitely be improved towards better classification."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4317862,"sourceId":7421410,"sourceType":"datasetVersion"}],"dockerImageVersionId":30636,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
